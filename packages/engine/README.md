# @sker/engine

AIå¤„ç†å¼•æ“æœåŠ¡åŒ… - ä¸º@sker/studioæä¾›å¼ºå¤§çš„AIå†…å®¹ç”Ÿæˆå’Œè¯­ä¹‰åˆ†æèƒ½åŠ›ã€‚

## ç³»ç»Ÿæ¶æ„ä½ç½®

`@sker/engine` æ˜¯SKERç³»ç»Ÿçš„**AIå¤„ç†å¼•æ“å±‚**ï¼Œè´Ÿè´£æ‰€æœ‰AIç›¸å…³çš„æ™ºèƒ½å¤„ç†ä»»åŠ¡ï¼š

```
APIç½‘å…³ (@sker/gateway)
        â†“ HTTPè°ƒç”¨
æ¶ˆæ¯ä»£ç† (@sker/broker)
        â†“ ä»»åŠ¡è°ƒåº¦
ğŸ“ AIå¼•æ“ (@sker/engine) â† å½“å‰æ¨¡å—
        â†“ ç»“æœå­˜å‚¨
æ•°æ®å­˜å‚¨ (@sker/store)
```

### æœåŠ¡è¿è¡Œæ¨¡å¼

**åŒæ¨¡å¼è¿è¡Œ**: @sker/engine æ”¯æŒä¸¤ç§è¿è¡Œæ¨¡å¼ï¼š

1. **ç‹¬ç«‹APIæœåŠ¡å™¨æ¨¡å¼**:
   ```bash
   # ç‹¬ç«‹è¿è¡Œï¼Œç›´æ¥ä¸ºå‰ç«¯æä¾›AIæœåŠ¡
   npm run server:dev  # é»˜è®¤ç«¯å£: 8000
   ```

2. **æ¶ˆæ¯é˜Ÿåˆ—é›†æˆæ¨¡å¼**:
   ```
   Gateway â†’ Broker â†’ Engine â†’ Store
   ```

### æœåŠ¡é—´é›†æˆå…³ç³»

- **ä»»åŠ¡æ¥æ”¶**: é€šè¿‡ä»¥ä¸‹æ–¹å¼æ¥æ”¶AIå¤„ç†è¯·æ±‚ï¼š
  - `@sker/broker`: æ¶ˆæ¯é˜Ÿåˆ—ä»»åŠ¡è°ƒåº¦ (æ¨èç”Ÿäº§ç¯å¢ƒ)
  - HTTP API: ç›´æ¥APIè°ƒç”¨ (å¼€å‘å’Œæµ‹è¯•)
- **æ•°æ®äº¤äº’**:
  - `@sker/store`: è¯»å–èŠ‚ç‚¹æ•°æ®ã€å­˜å‚¨å¤„ç†ç»“æœ
- **ä¾èµ–å…³ç³»**:
  ```json
  {
    "@sker/models": "workspace:*",
    "@sker/config": "workspace:*",
    "@sker/ai": "workspace:*"
  }
  ```

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### LLMé›†æˆç®¡ç†
- **å¤šæ¨¡å‹æ”¯æŒ**: é›†æˆOpenAI GPT-4ã€GPT-3.5-turboç­‰ä¸»æµæ¨¡å‹
- **æ™ºèƒ½æ¨¡å‹é€‰æ‹©**: æ ¹æ®ä»»åŠ¡ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„æ¨¡å‹
- **è´Ÿè½½å‡è¡¡**: åˆ†é…è¯·æ±‚åˆ°ä¸åŒçš„APIç«¯ç‚¹å’Œæ¨¡å‹
- **æˆæœ¬ä¼˜åŒ–**: æ™ºèƒ½é€‰æ‹©æˆæœ¬æ•ˆç›Šæœ€ä¼˜çš„æ¨¡å‹ç»„åˆ

### æ™ºèƒ½å†…å®¹ç”Ÿæˆ
- **æ–‡æœ¬ç”Ÿæˆ**: åŸºäºè¾“å…¥å’Œä¸Šä¸‹æ–‡ç”Ÿæˆé«˜è´¨é‡å†…å®¹
- **å†…å®¹ä¼˜åŒ–**: æ”¹è¿›ç°æœ‰å†…å®¹çš„è´¨é‡ã€ç»“æ„å’Œè¡¨è¾¾
- **å¤šè¾“å…¥èåˆ**: å°†å¤šä¸ªå†…å®¹æºæ™ºèƒ½èåˆä¸ºç»Ÿä¸€è¾“å‡º
- **æ‰©å±•ç”Ÿæˆ**: åŸºäºç°æœ‰å†…å®¹è¿›è¡Œç›¸å…³æ‰©å±•å’Œæ·±åŒ–

### è¯­ä¹‰åˆ†æå¤„ç†
- **è¯­ä¹‰ç†è§£**: æ·±åº¦åˆ†æå†…å®¹çš„è¯­ä¹‰ç»“æ„å’Œå«ä¹‰
- **æ ‡ç­¾æå–**: è‡ªåŠ¨è¯†åˆ«å’Œæå–å†…å®¹çš„å…³é”®æ ‡ç­¾
- **é‡è¦æ€§è¯„ä¼°**: æ™ºèƒ½è¯„ä¼°å†…å®¹çš„é‡è¦æ€§ç­‰çº§
- **ç½®ä¿¡åº¦è®¡ç®—**: è¯„ä¼°AIç”Ÿæˆå†…å®¹çš„å¯ä¿¡åº¦

### æç¤ºè¯å·¥ç¨‹
- **æ¨¡æ¿ç®¡ç†**: é¢„å®šä¹‰å’Œç®¡ç†å„ç§ä»»åŠ¡çš„æç¤ºè¯æ¨¡æ¿
- **åŠ¨æ€æ„å»º**: æ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€æ„å»ºæœ€ä¼˜æç¤ºè¯
- **A/Bæµ‹è¯•**: æµ‹è¯•ä¸åŒæç¤ºè¯çš„æ•ˆæœå·®å¼‚
- **æŒç»­ä¼˜åŒ–**: åŸºäºåé¦ˆæŒç»­æ”¹è¿›æç¤ºè¯è´¨é‡

## ğŸ“¦ ä¸»è¦æ¨¡å—

### AI Processing Engine
```typescript
import { AIEngine } from '@sker/engine'

const engine = new AIEngine({
  provider: 'openai',
  apiKey: process.env.OPENAI_API_KEY,
  models: {
    generation: 'gpt-4',
    optimization: 'gpt-3.5-turbo',
    analysis: 'gpt-4'
  }
})

// å¤„ç†AIä»»åŠ¡ - ä½¿ç”¨ç»Ÿä¸€çš„ä»»åŠ¡ç±»å‹
const result = await engine.processTask({
  type: 'generate',  // ç»Ÿä¸€ä»»åŠ¡ç±»å‹: 'generate' | 'optimize' | 'fusion' | 'analyze' | 'expand'
  inputs: ['ç”¨æˆ·è¾“å…¥å†…å®¹'],
  context: 'ä¸Šä¸‹æ–‡ä¿¡æ¯'
})
```

### Content Generator
```typescript
import { ContentGenerator } from '@sker/engine'

const generator = new ContentGenerator(engine)

// ç”Ÿæˆå†…å®¹
const content = await generator.generate({
  prompt: 'åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆåˆ†ææŠ¥å‘Š',
  inputs: ['æ•°æ®1', 'æ•°æ®2'],
  style: 'professional',
  length: 'medium'
})
```

### Semantic Analyzer
```typescript
import { SemanticAnalyzer } from '@sker/engine'

const analyzer = new SemanticAnalyzer(engine)

// è¯­ä¹‰åˆ†æ
const analysis = await analyzer.analyze(content, {
  extractTags: true,
  assessImportance: true,
  calculateConfidence: true
})
```

## ğŸ”§ å¤„ç†ç±»å‹

> **é‡è¦**: ä» v2.0 å¼€å§‹ï¼Œæ‰€æœ‰ä»»åŠ¡ç±»å‹å·²ç»Ÿä¸€ä¸º `@sker/models` åŒ…ä¸­çš„å®šä¹‰ï¼Œç¡®ä¿ä¸brokeræœåŠ¡çš„å®Œå…¨å…¼å®¹ã€‚

### å†…å®¹ç”Ÿæˆ (Generate)
- **åˆ›æ„å†™ä½œ**: åŸºäºä¸»é¢˜ç”Ÿæˆåˆ›æ„å†…å®¹
- **æŠ€æœ¯æ–‡æ¡£**: ç”ŸæˆæŠ€æœ¯è¯´æ˜å’Œæ–‡æ¡£
- **åˆ†ææŠ¥å‘Š**: åŸºäºæ•°æ®ç”Ÿæˆåˆ†æç»“è®º
- **è§£å†³æ–¹æ¡ˆ**: é’ˆå¯¹é—®é¢˜æä¾›è§£å†³æ–¹æ¡ˆ

### å†…å®¹ä¼˜åŒ– (Optimize)
- **è¯­è¨€æ”¹è¿›**: æå‡è¡¨è¾¾çš„æ¸…æ™°åº¦å’Œæµç•…æ€§
- **ç»“æ„ä¼˜åŒ–**: æ”¹å–„å†…å®¹çš„é€»è¾‘ç»“æ„
- **é£æ ¼è°ƒæ•´**: è°ƒæ•´å†…å®¹é£æ ¼ä»¥é€‚åº”ç‰¹å®šåœºæ™¯
- **é•¿åº¦æ§åˆ¶**: æ‰©å±•æˆ–å‹ç¼©å†…å®¹é•¿åº¦

### å¤šè¾“å…¥èåˆ (Fusion)
- **ç»¼åˆåˆ†æ**: èåˆå¤šä¸ªåˆ†æç»“æœ
- **è§‚ç‚¹æ•´åˆ**: æ•´åˆä¸åŒè§’åº¦çš„è§‚ç‚¹
- **æ•°æ®æ±‡æ€»**: æ±‡æ€»å¤šæºæ•°æ®çš„æ´å¯Ÿ
- **å†³ç­–æ”¯æŒ**: åŸºäºå¤šè¾“å…¥æä¾›å†³ç­–å»ºè®®

### è¯­ä¹‰åˆ†æ (Analyze)
- **å†…å®¹ç†è§£**: æ·±åº¦åˆ†æå†…å®¹çš„è¯­ä¹‰ç»“æ„
- **å…³é”®è¯æå–**: è¯†åˆ«å’Œæå–æ ¸å¿ƒæ¦‚å¿µ
- **æƒ…æ„Ÿåˆ†æ**: åˆ†ææ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘
- **ä¸»é¢˜è¯†åˆ«**: è¯†åˆ«æ–‡æœ¬çš„ä¸»è¦ä¸»é¢˜

### å†…å®¹æ‰©å±• (Expand)
- **æ·±åº¦æŒ–æ˜**: æ·±å…¥æ¢è®¨ç‰¹å®šä¸»é¢˜
- **ç›¸å…³æ‰©å±•**: æ‰©å±•ç›¸å…³çš„ä¸»é¢˜å’Œæ¦‚å¿µ
- **æ¡ˆä¾‹è¡¥å……**: æ·»åŠ ç›¸å…³æ¡ˆä¾‹å’Œå®ä¾‹
- **ç»†èŠ‚å®Œå–„**: è¡¥å……é‡è¦çš„ç»†èŠ‚ä¿¡æ¯

## ğŸš€ ä½¿ç”¨æ–¹å¼

### åŸºç¡€ä½¿ç”¨
```typescript
import { createEngine } from '@sker/engine'

const engine = await createEngine({
  provider: 'openai',
  apiKey: process.env.OPENAI_API_KEY,
  defaultModel: 'gpt-4',
  temperature: 0.7,
  maxTokens: 2000
})

// å¤„ç†ç”Ÿæˆä»»åŠ¡
const result = await engine.processGeneration({
  inputs: ['æˆ‘æƒ³åˆ›å»ºä¸€ä¸ªç”µå•†ç½‘ç«™'],
  instruction: 'åˆ†ææŠ€æœ¯éœ€æ±‚å’Œå®ç°æ–¹æ¡ˆ',
  context: 'é¢å‘ä¸­å°ä¼ä¸šçš„è§£å†³æ–¹æ¡ˆ'
})

console.log('Generated content:', result.content)
console.log('Confidence:', result.confidence)
console.log('Tags:', result.tags)
```

### é«˜çº§é…ç½®
```typescript
import { AIEngine, PromptTemplate } from '@sker/engine'

// è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿
const customTemplate = new PromptTemplate({
  name: 'business_analysis',
  template: `
ä½œä¸ºä¸€åä¸“ä¸šçš„å•†ä¸šåˆ†æå¸ˆï¼Œè¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼š

è¾“å…¥å†…å®¹ï¼š
{inputs}

ä¸Šä¸‹æ–‡ï¼š
{context}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æï¼š
1. å¸‚åœºæœºä¼š
2. æŠ€æœ¯å¯è¡Œæ€§
3. èµ„æºéœ€æ±‚
4. é£é™©è¯„ä¼°

æŒ‡å¯¼è¦æ±‚ï¼š
{instruction}

è¯·æä¾›ç»“æ„åŒ–çš„åˆ†ææŠ¥å‘Šã€‚
  `,
  variables: ['inputs', 'context', 'instruction']
})

const engine = new AIEngine({
  provider: 'openai',
  apiKey: process.env.OPENAI_API_KEY,
  templates: [customTemplate],
  retryConfig: {
    maxRetries: 3,
    backoffMultiplier: 2
  }
})

// ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿
const result = await engine.processWithTemplate('business_analysis', {
  inputs: ['å¼€å‘ç§»åŠ¨åº”ç”¨'],
  context: 'é¤é¥®è¡Œä¸šæ•°å­—åŒ–è½¬å‹',
  instruction: 'é‡ç‚¹å…³æ³¨æŠ•èµ„å›æŠ¥ç‡'
})
```

### æ‰¹é‡å¤„ç†
```typescript
import { BatchProcessor } from '@sker/engine'

const processor = new BatchProcessor(engine)

// æ‰¹é‡å¤„ç†å¤šä¸ªä»»åŠ¡
const results = await processor.processBatch([
  {
    type: 'generate',
    inputs: ['éœ€æ±‚1'],
    instruction: 'ç”ŸæˆæŠ€æœ¯æ–¹æ¡ˆ'
  },
  {
    type: 'analyze',
    inputs: ['ç°æœ‰æ–¹æ¡ˆ'],
    instruction: 'åˆ†æå¯è¡Œæ€§'
  },
  {
    type: 'optimize',
    inputs: ['åˆç¨¿å†…å®¹'],
    instruction: 'ä¼˜åŒ–è¡¨è¾¾å’Œç»“æ„'
  }
], {
  concurrency: 3,
  failFast: false
})

results.forEach((result, index) => {
  if (result.success) {
    console.log(`Task ${index} completed:`, result.content)
  } else {
    console.error(`Task ${index} failed:`, result.error)
  }
})
```

## ğŸ“‹ å¤„ç†ç»“æœæ ¼å¼

### æ ‡å‡†å¤„ç†ç»“æœ
```typescript
interface ProcessingResult {
  success: boolean
  content: string
  title?: string
  confidence: number
  tags: string[]
  reasoning?: string
  metadata: {
    model: string
    tokenCount: number
    processingTime: number
    temperature: number
    cost?: number
  }
  error?: {
    code: string
    message: string
    details?: any
  }
}
```

### è¯­ä¹‰åˆ†æç»“æœ
```typescript
interface SemanticAnalysis {
  semanticType: string
  importanceLevel: number
  keyTerms: string[]
  sentiment: 'positive' | 'neutral' | 'negative'
  complexity: 'low' | 'medium' | 'high'
  readability: number
  topics: Array<{
    name: string
    relevance: number
  }>
}
```

## ğŸ”§ é…ç½®è¯´æ˜

```typescript
interface EngineConfig {
  provider: 'openai' | 'anthropic' | 'custom'
  apiKey: string
  baseURL?: string
  organization?: string
  models: {
    generation?: string
    optimization?: string
    analysis?: string
    fusion?: string
  }
  defaultModel: string
  temperature: number
  maxTokens: number
  timeout: number
  retryConfig: {
    maxRetries: number
    backoffMultiplier: number
    retryableErrors: string[]
  }
  costOptimization: {
    enabled: boolean
    maxCostPerRequest: number
    preferredModels: string[]
  }
}
```

## ğŸ›¡ï¸ å®‰å…¨å’Œè´¨é‡

- **å†…å®¹è¿‡æ»¤**: è‡ªåŠ¨æ£€æµ‹å’Œè¿‡æ»¤ä¸å½“å†…å®¹
- **è¾“å…¥éªŒè¯**: ä¸¥æ ¼éªŒè¯è¾“å…¥å‚æ•°å’Œæ ¼å¼
- **è¾“å‡ºæ ¡éªŒ**: éªŒè¯AIè¾“å‡ºçš„è´¨é‡å’Œç›¸å…³æ€§
- **éšç§ä¿æŠ¤**: ç¡®ä¿æ•æ„Ÿä¿¡æ¯ä¸ä¼šæ³„éœ²
- **æˆæœ¬æ§åˆ¶**: ç›‘æ§å’Œæ§åˆ¶APIè°ƒç”¨æˆæœ¬

## ğŸŒ Studio API æœåŠ¡å™¨

@sker/engine ç°åœ¨æä¾›äº†å®Œæ•´çš„ API æœåŠ¡å™¨åŠŸèƒ½ï¼Œå¯ä»¥ç›´æ¥ä¸ºå‰ç«¯ Studio åº”ç”¨æä¾›æœåŠ¡ã€‚

### å¿«é€Ÿå¯åŠ¨ API æœåŠ¡å™¨

```bash
# 1. å¤åˆ¶ç¯å¢ƒå˜é‡é…ç½®
cp .env.example .env

# 2. é…ç½®ä½ çš„ OpenAI API Key
echo "OPENAI_API_KEY=your-api-key" >> .env

# 3. å¯åŠ¨æœåŠ¡å™¨
npm run server

# å¼€å‘æ¨¡å¼ï¼ˆæ”¯æŒçƒ­é‡è½½ï¼‰
npm run server:dev
```

### API ç«¯ç‚¹

æœåŠ¡å™¨é»˜è®¤è¿è¡Œåœ¨ `http://localhost:8000`ï¼Œæä¾›ä»¥ä¸‹ç«¯ç‚¹ï¼š

#### å¥åº·æ£€æŸ¥
- `GET /health` - æ£€æŸ¥æœåŠ¡å™¨å’ŒAIå¼•æ“çŠ¶æ€

#### AI å¤„ç†æ¥å£
- `POST /api/ai/generate` - ç”ŸæˆAIå†…å®¹
- `POST /api/ai/optimize` - ä¼˜åŒ–ç°æœ‰å†…å®¹
- `POST /api/ai/fusion` - å¤šè¾“å…¥èåˆç”Ÿæˆ
- `POST /api/ai/title` - ç”Ÿæˆæ ‡é¢˜
- `POST /api/ai/tags` - æå–æ ‡ç­¾
- `POST /api/ai/batch` - æ‰¹é‡å¤„ç†
- `POST /api/ai/semantics` - è¯­ä¹‰åˆ†æ
- `POST /api/ai/node/optimize` - èŠ‚ç‚¹ä¼˜åŒ–

#### çŠ¶æ€æŸ¥è¯¢
- `GET /api/ai/status/:nodeId` - è·å–å¤„ç†çŠ¶æ€
- `GET /api/ai/stats` - è·å–å¼•æ“ç»Ÿè®¡ä¿¡æ¯
- `GET /api/ai/models` - è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨

### API ä½¿ç”¨ç¤ºä¾‹

```typescript
// ç”Ÿæˆå†…å®¹
const response = await fetch('http://localhost:8000/api/ai/generate', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    inputs: ['æˆ‘æƒ³åˆ›å»ºä¸€ä¸ª AI åŠ©æ‰‹'],
    context: 'æ™ºèƒ½å®¢æœç³»ç»Ÿ',
    instruction: 'åˆ†ææŠ€æœ¯å®ç°æ–¹æ¡ˆ',
    options: {
      temperature: 0.7,
      maxTokens: 2000,
      model: 'gpt-4'
    }
  })
})

const result = await response.json()
console.log(result.data.content)
```

### ä¸å‰ç«¯ Studio é›†æˆ

å‰ç«¯ aiService é…ç½®ï¼š

```typescript
// apps/studio/src/services/aiService.ts
const defaultConfig: AIServiceConfig = {
  apiUrl: 'http://localhost:8000/api/ai',
  model: 'gpt-4',
  timeout: 30000,
  maxRetries: 3,
}
```

### ç¼–ç¨‹å¼ä½¿ç”¨

```typescript
import { createAndStartStudioAPIServer, AIEngine } from '@sker/engine'

// åˆ›å»º AI å¼•æ“
const aiEngine = new AIEngine({
  openai: {
    apiKey: process.env.OPENAI_API_KEY
  }
})

// å¯åŠ¨ API æœåŠ¡å™¨
const server = await createAndStartStudioAPIServer(aiEngine, {
  port: 8000,
  cors: {
    origin: ['http://localhost:3000']
  }
})

console.log('Server running at http://localhost:8000')
```

## ğŸ“Š ç›‘æ§æŒ‡æ ‡

- å¤„ç†æˆåŠŸç‡å’Œå¤±è´¥ç‡
- å¹³å‡å¤„ç†æ—¶é—´å’Œå“åº”å»¶è¿Ÿ
- Tokenä½¿ç”¨é‡å’Œæˆæœ¬ç»Ÿè®¡
- æ¨¡å‹æ€§èƒ½å’Œå‡†ç¡®åº¦
- é”™è¯¯ç±»å‹å’Œé¢‘ç‡åˆ†æ
- API è¯·æ±‚ç»Ÿè®¡å’Œæ€§èƒ½ç›‘æ§

## ğŸ”§ ç¯å¢ƒå˜é‡é…ç½®

```bash
# AI å¼•æ“é…ç½®
OPENAI_API_KEY=your-openai-api-key
OPENAI_DEFAULT_MODEL=gpt-3.5-turbo
OPENAI_TIMEOUT=30000

# æœåŠ¡å™¨é…ç½®
STUDIO_API_PORT=8000
STUDIO_API_HOST=0.0.0.0
STUDIO_CORS_ORIGIN=http://localhost:3000,http://localhost:5173

# ç¼“å­˜å’Œé™æµ
CACHE_ENABLED=true
RATE_LIMIT_ENABLED=true
RATE_LIMIT_RPM=60

# å¼€å‘ç¯å¢ƒ
NODE_ENV=development
```

ä¸º@sker/studioæä¾›å¼ºå¤§ã€å¯é ã€é«˜æ•ˆçš„AIå¤„ç†èƒ½åŠ›ï¼Œè®©æ™ºèƒ½å†…å®¹ç”Ÿæˆå˜å¾—ç®€å•è€Œç²¾ç¡®ã€‚