#!/usr/bin/env node

import dotenv from 'dotenv'
import { AIEngine } from '../core/AIEngine.js'
import { StudioAPIServer } from './StudioAPIServer.js'
import { MessageBroker } from '@sker/broker'
import { StoreClient } from '@sker/store-client'
import { AITaskQueueConsumer } from '../messaging/AITaskQueueConsumer.js'

// åŠ è½½ç¯å¢ƒå˜é‡
dotenv.config()

/**
 * æœåŠ¡å™¨å¯åŠ¨è„šæœ¬
 */
async function main() {
  try {
    const runMode = process.env.ENGINE_RUN_MODE || 'http' // 'http', 'queue', 'both'
    console.log(`ğŸš€ å¯åŠ¨ SKER Engine (æ¨¡å¼: ${runMode})...`)

    // åˆ›å»º AI å¼•æ“å®ä¾‹
    const aiEngine = new AIEngine({
      provider: 'openai',
      apiKey: process.env.OPENAI_API_KEY || '',
      baseURL: process.env.OPENAI_BASE_URL,
      defaultModel: process.env.OPENAI_DEFAULT_MODEL || 'gpt-3.5-turbo',
      temperature: 0.7,
      maxTokens: 4000,
      timeout: parseInt(process.env.OPENAI_TIMEOUT || '30000'),
      models: {
        generation: 'gpt-3.5-turbo',
        optimization: 'gpt-3.5-turbo',
        analysis: 'gpt-3.5-turbo',
        fusion: 'gpt-3.5-turbo'
      },
      model: {
        name: process.env.OPENAI_DEFAULT_MODEL || 'gpt-3.5-turbo',
        maxTokens: 4000
      },
      retryConfig: {
        maxRetries: parseInt(process.env.OPENAI_MAX_RETRIES || '3'),
        backoffMultiplier: 2,
        retryableErrors: ['ECONNRESET', 'ENOTFOUND', 'ECONNREFUSED', 'ETIMEDOUT']
      }
    })

    let apiServer: StudioAPIServer | undefined
    let queueConsumer: AITaskQueueConsumer | undefined

    // æ ¹æ®è¿è¡Œæ¨¡å¼å¯åŠ¨ç›¸åº”æœåŠ¡
    if (runMode === 'http' || runMode === 'both') {
      // å¯åŠ¨HTTP APIæœåŠ¡å™¨
      apiServer = new StudioAPIServer(aiEngine, {
        port: parseInt(process.env.STUDIO_API_PORT || '8000'),
        host: process.env.STUDIO_API_HOST || '0.0.0.0',
        cors: {
          origin: process.env.STUDIO_CORS_ORIGIN?.split(',') || [
            'http://localhost:3000',
            'http://localhost:5173',
            'http://localhost:8080'
          ],
          credentials: true
        },
        rateLimit: {
          windowMs: parseInt(process.env.API_RATE_LIMIT_WINDOW || '900000'), // 15åˆ†é’Ÿ
          max: parseInt(process.env.API_RATE_LIMIT_MAX || '100'),
          message: 'è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•'
        },
        timeout: parseInt(process.env.API_TIMEOUT || '120000'), // 2åˆ†é’Ÿ
        environment: (process.env.NODE_ENV as any) || 'development'
      })

      await apiServer.start()
      console.log('âœ… HTTP APIæœåŠ¡å™¨å¯åŠ¨æˆåŠŸ')
    }

    if (runMode === 'queue' || runMode === 'both') {
      // å¯åŠ¨é˜Ÿåˆ—æ¶ˆè´¹è€…
      const messageBroker = new MessageBroker({
        connectionUrl: process.env.RABBITMQ_URL || 'amqp://localhost:5672',
        exchanges: {
          'llm.direct': {
            type: 'direct',
            durable: true
          }
        },
        queues: {
          'ai.tasks': {
            durable: true
          }
        },
        retry: {
          maxRetries: parseInt(process.env.QUEUE_RETRY_ATTEMPTS || '3'),
          maxAttempts: parseInt(process.env.QUEUE_RETRY_ATTEMPTS || '3'),
          initialDelay: parseInt(process.env.QUEUE_RETRY_DELAY || '1000'),
          maxDelay: parseInt(process.env.QUEUE_RETRY_MAX_DELAY || '10000'),
          backoffMultiplier: parseFloat(process.env.QUEUE_RETRY_BACKOFF || '2'),
          retryableErrors: ['ENOTFOUND', 'ECONNRESET', 'TIMEOUT']
        }
      })

      const storeClient = new StoreClient({
        baseURL: process.env.STORE_API_URL || 'http://localhost:3001',
        authToken: process.env.STORE_AUTH_TOKEN,
        timeout: parseInt(process.env.STORE_TIMEOUT || '30000')
      })

      queueConsumer = new AITaskQueueConsumer(
        messageBroker,
        aiEngine,
        storeClient,
        {
          concurrency: parseInt(process.env.QUEUE_CONCURRENCY || '5'),
          retryAttempts: parseInt(process.env.QUEUE_RETRY_ATTEMPTS || '3'),
          prefetchCount: parseInt(process.env.QUEUE_PREFETCH_COUNT || '10')
        }
      )

      await queueConsumer.start()
      console.log('âœ… é˜Ÿåˆ—æ¶ˆè´¹è€…å¯åŠ¨æˆåŠŸ')
    }

    // æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
    console.log(`âœ… SKER Engine å¯åŠ¨å®Œæˆ! (æ¨¡å¼: ${runMode})`)
    
    let status: any = null
    if (apiServer) {
      status = apiServer.getStatus()
      console.log(`ğŸ“ HTTP API åœ°å€: http://${status.host}:${status.port}`)
      console.log(`ğŸŒ è¿è¡Œç¯å¢ƒ: ${status.environment}`)
      console.log(`ğŸ”— API æ ¹è·¯å¾„: http://${status.host}:${status.port}/api/ai`)
      console.log(`â¤ï¸  å¥åº·æ£€æŸ¥: http://${status.host}:${status.port}/health`)

      if (status.environment === 'development') {
        console.log(`ğŸ“š API æ–‡æ¡£: http://${status.host}:${status.port}/docs`)
      }
    }

    if (queueConsumer) {
      const queueStats = queueConsumer.getStats()
      console.log(`ğŸ¯ é˜Ÿåˆ—æ¶ˆè´¹è€…çŠ¶æ€: ${queueStats.isRunning ? 'è¿è¡Œä¸­' : 'å·²åœæ­¢'}`)
      console.log(`ğŸ“Š å¹¶å‘å¤„ç†æ•°: ${queueStats.config.concurrency}`)
      console.log(`ğŸ”„ é‡è¯•æ¬¡æ•°: ${queueStats.config.retryAttempts}`)
    }

    // ä¼˜é›…å…³é—­å¤„ç†
    const shutdownHandler = async (signal: string) => {
      console.log(`\næ”¶åˆ° ${signal} ä¿¡å·ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...`)
      try {
        const shutdownPromises: Promise<void>[] = []

        if (apiServer) {
          shutdownPromises.push(apiServer.stop())
        }

        if (queueConsumer) {
          shutdownPromises.push(queueConsumer.stop())
        }

        await Promise.all(shutdownPromises)
        console.log('âœ… EngineæœåŠ¡å·²ä¼˜é›…å…³é—­')
        process.exit(0)
      } catch (error) {
        console.error('âŒ å…³é—­EngineæœåŠ¡æ—¶å‡ºé”™:', error)
        process.exit(1)
      }
    }

    // æ³¨å†Œä¿¡å·å¤„ç†å™¨
    process.on('SIGTERM', () => shutdownHandler('SIGTERM'))
    process.on('SIGINT', () => shutdownHandler('SIGINT'))
    process.on('SIGUSR2', () => shutdownHandler('SIGUSR2')) // nodemon é‡å¯ä¿¡å·

    // å¼€å‘ç¯å¢ƒä¸‹çš„çƒ­é‡è½½æ”¯æŒ
    if (status && status.environment === 'development') {
      console.log('ğŸ”¥ å¼€å‘æ¨¡å¼å·²å¯ç”¨ - æ”¯æŒçƒ­é‡è½½')
    }

  } catch (error) {
    console.error('âŒ å¯åŠ¨æœåŠ¡å™¨å¤±è´¥:', error)

    // æ˜¾ç¤ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œè§£å†³å»ºè®®
    if (error instanceof Error) {
      console.error('é”™è¯¯è¯¦æƒ…:', error.message)

      // å¸¸è§é”™è¯¯çš„è§£å†³å»ºè®®
      if (error.message.includes('EADDRINUSE')) {
        console.log('\nğŸ’¡ è§£å†³å»ºè®®:')
        console.log('  - ç«¯å£å·²è¢«å ç”¨ï¼Œè¯·æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–æœåŠ¡åœ¨è¿è¡Œ')
        console.log('  - å°è¯•æ›´æ”¹ STUDIO_API_PORT ç¯å¢ƒå˜é‡')
        console.log('  - ä½¿ç”¨ lsof -ti :8000 | xargs kill åœæ­¢å ç”¨ç«¯å£çš„è¿›ç¨‹')
      } else if (error.message.includes('OPENAI_API_KEY')) {
        console.log('\nğŸ’¡ è§£å†³å»ºè®®:')
        console.log('  - è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡')
        console.log('  - åˆ›å»º .env æ–‡ä»¶å¹¶æ·»åŠ : OPENAI_API_KEY=your-api-key')
      } else if (error.message.includes('network') || error.message.includes('timeout')) {
        console.log('\nğŸ’¡ è§£å†³å»ºè®®:')
        console.log('  - æ£€æŸ¥ç½‘ç»œè¿æ¥')
        console.log('  - ç¡®è®¤ OpenAI API æœåŠ¡å¯è®¿é—®')
        console.log('  - æ£€æŸ¥ä»£ç†è®¾ç½®')
      }
    }

    process.exit(1)
  }
}

// æœªæ•è·å¼‚å¸¸å¤„ç†
process.on('uncaughtException', (error: Error) => {
  console.error('ğŸ’¥ æœªæ•è·çš„å¼‚å¸¸:', error)
  process.exit(1)
})

process.on('unhandledRejection', (reason: any, promise: Promise<any>) => {
  console.error('ğŸ’¥ æœªå¤„ç†çš„ Promise æ‹’ç»:', reason)
  process.exit(1)
})

// å¯åŠ¨åº”ç”¨
if (import.meta.url === `file://${process.argv[1]}`) {
  main().catch((error) => {
    console.error('ğŸ’¥ åº”ç”¨å¯åŠ¨å¤±è´¥:', error)
    process.exit(1)
  })
}